# -*- coding: utf-8 -*-

#~~~~~~~~~~~~~~IMPORTS~~~~~~~~~~~~~~#
# Std lib
import collections, os, traceback, datetime
import multiprocessing as mp

# Third party
from loguru import logger
import yaml
#from tqdm import tqdm
import numpy as np
from pyfaidx import Fasta

# Local package
from nanocompore.common import *
import nanocompore.SampCompResultsmanager as SampCompResultsmanager
import nanocompore.Transcript as Transcript
import nanocompore.TxComp as TxComp
import nanocompore.Whitelist as Whitelist
import nanocompore.Experiment as Experiment

import nanocompore as pkg


# Disable multithreading for MKL and openBlas
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["MKL_THREADING_LAYER"] = "sequential"
os.environ["NUMEXPR_NUM_THREADS"] = "1"
os.environ["OMP_NUM_THREADS"] = "1"
os.environ['OPENBLAS_NUM_THREADS'] = '1'

#~~~~~~~~~~~~~~MAIN CLASS~~~~~~~~~~~~~~#
class SampComp(object):
    """ Init analysis and check args"""

    #~~~~~~~~~~~~~~FUNDAMENTAL METHODS~~~~~~~~~~~~~~#

    def __init__(self,
        in_tsv:str,
        fasta_fn:str,
        bed_fn:str = None,
        outpath:str = "results",
        outprefix:str = "out_",
        overwrite:bool = False,
        whitelist:Whitelist = None,
        comparison_methods:list = ["GMM", "KS"],
        logit:bool = True,
        anova:bool = False,
        allow_warnings:bool = False,
        sequence_context:int = 0,
        sequence_context_weights:str = "uniform",
        min_coverage:int = 30,
        min_ref_length:int = 100,
        downsample_high_coverage:int = 5000,
        max_invalid_kmers_freq:float = 0.1,
        select_ref_id:list = [],
        exclude_ref_id:list = [],
        nthreads:int = 2,
        progress:bool = False):


        """
        Initialise a `SampComp` object and generates a white list of references with sufficient coverage for subsequent analysis.
        The retuned object can then be called to start the analysis.
        * fn_dict
            Multilevel dictionnary indicating the condition_label, sample_label and 
            the file name of the pod5 file with corresponding bam file
            2 conditions are expected and at least 2 sample replicates per condition are highly recommended.
            One can also pass TSV file describing the samples instead in the format:

            Cond_1\tSamp_0\tpath1.pod5\tpath1.bam
            Cond_1\tSamp_1\tpath2.pod5\tpath2.bam
            Cond_2\tSamp_0\tpath3.pod5\tpath3.bam
            Cond_2\tSamp_1\tpath4.pod5\tpath4.bam

            example d = {"S1": {"R1":{'pod5':"path1.pod5", 'bam':"path1.bam"},
                                "R2":{'pod5':"path2.pod5", 'bam':"path2.bam"}}, 
                         "S2": {"R1":{'pod5':"path3.pod5", 'bam':"path3.bam"},
                                "R2":{'pod5':"path4.pod5", 'bam':"path4.bam"}}
        * outpath
            Path to the output folder.
        * outprefix
            text outprefix for all the files generated by the function.
        * overwrite
            If the output directory already exists, the standard behaviour is to raise an error to prevent overwriting existing data
            This option ignore the error and overwrite data if they have the same outpath and outprefix.
        * fasta_fn
            Path to a fasta file corresponding to the reference used for read alignment.
        * bed_fn
            Path to a BED file containing the annotation of the transcriptome used as reference when mapping.
        * whitelist
            Whitelist object previously generated with nanocompore Whitelist. If not given, will be automatically generated.
        * comparison_methods
            Statistical method to compare the 2 samples (mann_whitney or MW, kolmogorov_smirnov or KS, t_test or TT, gaussian_mixture_model or GMM).
            This can be a list or a comma separated string. {MW,KS,TT,GMM}
        * logit
            Force logistic regression even if we have less than 2 replicates in any condition.
        * allow_warnings
            If True runtime warnings during the ANOVA tests don't raise an error.
        * sequence_context
            Extend statistical analysis to contigous adjacent base if available.
        * sequence_context_weights
            type of weights to used for combining p-values. {uniform,harmonic}
        * min_coverage
            minimal read coverage required in all sample.
        * min_ref_length
            minimal length of a reference transcript to be considered in the analysis
        * downsample_high_coverage
            For reference with higher coverage, downsample by randomly selecting reads.
        * max_invalid_kmers_freq
            maximum frequency of NNNNN, mismatching and missing kmers in reads.
        * select_ref_id
            if given, only reference ids in the list will be selected for the analysis.
        * exclude_ref_id
            if given, refid in the list will be excluded from the analysis.
        * nthreads
            Number of threads (two are used for reading and writing, all the others for parallel processing).
        * progress
            Display a progress bar during execution
        """
        logger.info("Checking and initialising SampComp")

        # Save init options in dict for later
        log_init_state(loc=locals())


        # Check if fasta and bed files exist
        if not access_file(fasta_fn):
            raise NanocomporeError("{} is not a valid FASTA file".format(fasta_fn))

        self._test_open_fasta_file(fasta_fn)

        if bed_fn and not access_file(bed_fn):
            raise NanocomporeError("{} is not a valid BED file".format(bed_fn))

        # Check threads number
        if nthreads < 3:
            raise NanocomporeError("The minimum number of threads is 3")

        # Parse comparison methods
        if comparison_methods:
            self._comparison_methods = self._format_comparison_methods(comparison_methods)
        else:
            raise NanocomporeError("No comparison methods listed")

        #set the output prefix
        self._outprefix = self._format_output_prefix(outprefix)
        
        #if no outpath was provided, make it the current working directory
        self._set_outpath(outpath)

        # Set private args
        self._experiment = Experiment.Experiment(in_tsv)

        self._overwrite=overwrite
        self._min_coverage = min_coverage
        self._max_coverage = downsample_high_coverage
        self._min_ref_length = min_ref_length
        self._bed_fn = bed_fn
        self._logit = logit
        self._anova = anova
        self._allow_warnings = allow_warnings
        self._sequence_context = sequence_context
        self._sequence_context_weights = sequence_context_weights
        self._nthreads = nthreads - 2
        self._progress = progress
        self._select_ref_ids = select_ref_id
        self._exclude_ref_ids = exclude_ref_id


        logger.info("Starting to whitelist the reference IDs")
        self._Whitelist = Whitelist.Whitelist(experiment=self._experiment,
                                    fasta_fn=self._fasta_fn,
                                    min_coverage=self._min_coverage,
                                    min_ref_length=self._min_ref_length,
                                    select_ref_id=self._select_ref_ids,
                                    exclude_ref_id=self._exclude_ref_ids)

        self._valid_transcripts = self._Whitelist.ref_id_list

   #~~~~~~~~~~~~~~PRIVATE data processing METHODs~~~~~~~~~~~~~~#

    def _set_outpath(self, outpath):
        if outpath:
            self._outpath = outpath
        else:
            self._outpath = os.getcwd()

    def _format_output_prefix(self, outprefix):
        if outprefix and outprefix.endswith('_'):
            prefix = outprefix
        elif outprefix and not outprefix.endswith('_'):
            prefix = f"{outprefix}_"
        else:
            prefix = "out_"
        return prefix

    def _format_comparison_methods(self, comparison_methods): 
        if type(comparison_methods) == str:
            comparison_methods = comparison_methods.split(",")
        for i, method in enumerate(comparison_methods):
            method = method.upper()
            if method in ["MANN_WHITNEY", "MW"]:
                comparison_methods[i]="MW"
            elif method in ["KOLMOGOROV_SMIRNOV", "KS"]:
                comparison_methods[i]="KS"
            elif method in ["T_TEST", "TT"]:
                comparison_methods[i]="TT"
            elif method in ["GAUSSIAN_MIXTURE_MODEL", "GMM"]:
                comparison_methods[i]="GMM"
            else:
                raise NanocomporeError(f"Invalid comparison method {method}")
        return comparison_methods


    #~~~~~~~~~~~~~~Call METHOD~~~~~~~~~~~~~~#
    def __call__(self):
        """
        Run the analysis
        """
        logger.info("Starting data processing")

        in_q = mp.Queue(maxsize = 100)
        out_q = mp.Queue(maxsize = 100)
        error_q = mp.Queue(maxsize = 100)

        for tx in self._valid_transcripts:
            in_q.put(tx)
        
        self.resultsManager = SampCompResultsmanager.resultsManager(outpath=self._outpath, 
                                                                    prefix=self._outprefix, 
                                                                    overwrite=self._overwrite,
                                                                    bed_annotation=self._bed_fn,
                                                                    correction_method='fdr_bh')

        self.txComp = TxComp.TxComp(experiment=self._experiment,
                                    random_state = 26,
                                    methods=self._comparison_methods,
                                    sequence_context=self._sequence_context,
                                    min_coverage=self._min_coverage,
                                    sequence_context_weights=self._sequence_context_weights,
                                    anova=self._anova,
                                    logit=self._logit,
                                    allow_warnings=self._allow_warnings)
        # Define processes
        processes = list()
        #TODO delete?
        #processes.append(mp.Process(target=self._list_refid, args=(in_q, error_q)))
        processes.append(mp.Process(target=self._writeResults, args=(out_q, error_q)))
        for i in range(self._nthreads):
            in_q.put(None)
            processes.append(mp.Process(target=self._processTx, args=(in_q, out_q, error_q)))

        try:
            #Start all processes
            self._fasta_fh = Fasta(self._fasta_fn)
            for p in processes:
                p.start()

            # Monitor error queue
            for tb in iter(error_q.get, None):
                logger.trace("Error caught from error_q")
                raise NanocomporeError(tb)
            logger.debug("Error queue was closed")
            
            # Soft processes and queues stopping
            logger.debug("Waiting for all processes to be joined")
            for p in processes:
                p.join()
            logger.debug("All processes joined successfully")

            logger.debug("Closing all queues")
            for q in (in_q, out_q, error_q):
                q.close()
            logger.debug("All queues were closed")

            self.resultsManager.finish()

        except Exception as E:
            logger.error("An error occured. Killing all processes and closing queues\n")
            try:
                for p in processes:
                    p.terminate()
                for q in (in_q, out_q, error_q):
                    q.close()
            except:
                logger.error("An error occured while trying to kill processes\n")
            raise E
        finally:
            self.resultsManager.closeDB()
            self._fasta_fh.close()


    #~~~~~~~~~~~~~~PRIVATE MULTIPROCESSING METHOD~~~~~~~~~~~~~~#
    def _processTx(self, in_q, out_q, error_q):
        logger.debug("Worker thread started")
        try:
            n_tx = 0
            for ref_id in iter(in_q.get, None):
                logger.debug(f"Worker thread processing new item from in_q: {ref_id}")
                ref_seq = str(self._fasta_fh[ref_id])
                transcript = Transcript.Transcript(ref_id=ref_id, experiment=self._experiment, ref_seq=ref_seq,
                                                   min_coverage=self._min_coverage, max_coverage=self._max_coverage)
                try:
                    n_tx += 1
                    logger.debug(f"Collecting data for {ref_id}")
                    results = self.txComp.txCompare(transcript)
                    out_q.put((transcript.name, results))
                except:
                    logger.debug(f"Insufficent coverage for {ref_id} skipping transcript")

        except:
            logger.error("Error in Worker")
            error_q.put(NanocomporeError(traceback.format_exc()))

        # Deal poison pill and close file pointer
        finally:
            logger.debug(f"Processed Transcrits: {n_tx}")
            logger.debug("Adding poison pill to out_q")
            out_q.put(None)

    def _writeResults(self, out_q, error_q):
        #TODO need to determine if this is necessary
        #self.resultsManager.saveExperimentMetadata()

        try:
            n_tx = 0
            n_pos = 0
            for _ in range(self._nthreads):
                for tx, result in iter(out_q.get, None):
                    if result:
                        logger.debug(f"Writer thread adding results data from {tx}")
                        n_tx += 1
                        n_pos = len([x for x in result if type(x) == int])
                        self.resultsManager.saveData(tx, result)
            self.resultsManager.finish()
        except:
            logger.error("Error writing results to database")
            error_q.put(NanocomporeError(traceback.format_exc()))
        finally:
            logger.debug("Written Transcripts:{} Valid positions:{}".format(n_tx, n_pos))
            self.resultsManager.closeDB()
            logger.info ("All Done. Transcripts processed: {}".format(n_tx))
            # Kill error queue with poison pill
            error_q.put(None)

    #TODO delete?
    def _list_refid(self, in_q, error_q):
        """Add valid refid from whitelist to input queue to dispatch the data among the workers"""
        n_tx = 0
        try:
            for tx in self._valid_transcripts:
                logger.debug(f"Adding {tx} to in_q")
                in_q.put((tx))
                n_tx+=1

        # Manage exceptions and add error trackback to error queue
        except Exception:
            logger.debug("Error in Reader")
            error_q.put(traceback.format_exc())

        # Deal poison pills
        finally:
            for i in range (self._nthreads):
                in_q.put(None)
            logger.debug(f"Parsed transcripts:{n_tx}")

    def _test_open_fasta_file(self, fasta_fn):
        # Test that Fasta can be opened
        try:
            with Fasta(fasta_fn):
                self._fasta_fn = fasta_fn
        except IOError:
            raise NanocomporeError("The fasta file cannot be opened")